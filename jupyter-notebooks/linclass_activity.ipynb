{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Linear Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the olive oil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = pd.read_csv('olive_oils.csv')\n",
    "print(oil.shape)\n",
    "oil.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting five features against one another for the sake of space. We have 7 features, so if you have\n",
    "# a large enough screen, feel free to change 5 to 7 below and see all pairs of features.\n",
    "\n",
    "labels = set(oil['area_name'].values)\n",
    "fig, axs = plt.subplots(5,5, figsize = (20, 20))\n",
    "#print(axs)\n",
    "for label in labels:\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            if i != j:\n",
    "                axs[i, j].plot(oil.loc[oil['area_name'] == label].iloc[:,i+1], \n",
    "                               oil.loc[oil['area_name'] == label].iloc[:,j+1], 'o', label = label)\n",
    "            if i == j:\n",
    "                #axs[i,j].set_title(oil.columns[i+1])\n",
    "                axs[i,j].text(0.5, 0.5,oil.columns[i+1], horizontalalignment='center',\n",
    "                     verticalalignment='center', transform = axs[i,j].transAxes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for label in labels:\n",
    "    plt.plot(oil.loc[oil['area_name'] == label]['palmitic'], \n",
    "                               oil.loc[oil['area_name'] == label]['linoleic'], 'o', label = label)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which classes look like they will be relatively easy to identify? Which classes will be difficult?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training and testing data\n",
    "\n",
    "We're going to use 400 instances from this data set as our training set, and the remaining 172 as a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.random.choice(oil.index, 400, replace = False)\n",
    "oil_train = oil.loc[train_idx,:]\n",
    "oil_test = oil.drop(train_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization, we'll use just two of the variables here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  # As with many other models, these perform better with scaled data\n",
    "X = scaler.fit_transform(oil_train[['palmitic', 'linoleic']])\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(oil_train['area_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are helper functions for plotting the decision regions.\n",
    "# Code from StackOverflow user seralouk, comments my own\n",
    "\n",
    "def make_meshgrid(x, y, h=0.02): # If you are using unscaled data, change h to about 2 to avoid out-of-memory errors\n",
    "    x_min, x_max = x.min() - 0.5, x.max() + 0.5\n",
    "    y_min, y_max = y.min() - 0.5, y.max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: plotting the decision surface of a linear support vector classifier\n",
    "\n",
    "model = SVC(kernel='linear', gamma = 'scale')\n",
    "clf = model.fit(X, y)\n",
    "\n",
    "title = ('Decision surface of linear SVC')\n",
    "X0, X1 = X[:,0], X[:,1]\n",
    "xx, yy = make_meshgrid(X0, X1, h = 0.02) # Unscaled data -- don't forget to set h!!\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "cf = plot_contours(ax, clf, xx, yy, cmap=plt.cm.Pastel2, alpha=0.8)\n",
    "\n",
    "for label in labels:\n",
    "    ax.scatter(X0[oil_train['area_name'] == label], \n",
    "               X1[oil_train['area_name'] == label], \n",
    "               marker = 'o', edgecolor = 'black', label = label)\n",
    "\n",
    "ax.set_ylabel('Linoleic')\n",
    "ax.set_xlabel('Palmitic')\n",
    "ax.set_title(title)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Now let's use the same code with a `LogisticRegression` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver = 'lbfgs', penalty = 'none', multi_class='ovr')\n",
    "clf.fit(X, y)\n",
    "title = ('Decision surface of logistic regression')\n",
    "X0, X1 = X[:,0], X[:,1]\n",
    "xx, yy = make_meshgrid(X0, X1, h = 0.02)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "plot_contours(ax, clf, xx, yy, cmap=plt.cm.Pastel2, alpha=0.8)\n",
    "for label in sorted(labels):\n",
    "    ax.scatter(X0[oil_train['area_name'] == label], \n",
    "               X1[oil_train['area_name'] == label], \n",
    "               marker = 'o', edgecolor = 'black', label = label)\n",
    "\n",
    "ax.set_ylabel('Linoleic')\n",
    "ax.set_xlabel('Palmitic')\n",
    "ax.set_title(title)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What qualitative differences do you notice between the decision boundaries for logistic regression and those for the linear SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training and testing data for model validation\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Using the same train/test set as before, set up testing and training `X` and `y`, but this time:\n",
    "* use all predictors in `X` instead of just 2\n",
    "* don't run `y` through the `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "The following code uses five-fold cross-validation to find a good value of `C` to use for a linear SVM. This runs through a number of values of `C`. Assumes your training data are called `X_train`, `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 200\n",
    "min_C = 0.1\n",
    "max_C = 20\n",
    "scores = np.zeros(n_trials)\n",
    "\n",
    "C_range = np.linspace(min_C, max_C, n_trials)\n",
    "\n",
    "i = 0\n",
    "for C in C_range:\n",
    "    model = SVC(kernel='linear', gamma = 'scale', C = C)\n",
    "    score = cross_val_score(model, X_train, y_train, cv = 5)\n",
    "    scores[i] = np.average(score)\n",
    "    i += 1\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(C_range, scores, '.')\n",
    "plt.xlabel(\"Value of C\")\n",
    "plt.ylabel(\"5-CV accuracy score\")\n",
    "plt.show()\n",
    "\n",
    "best_C_lin = C_range[np.argmax(scores)]\n",
    "print(\"Best value of C found:\", best_C_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Repeat the above process, but use a radial basis function kernel (set `kernel = 'rbf'`, `gamma = 'auto'` when initializing your `SVC` instance). Plot the accuracy against the value of `C` and report the best value of `C`. (You can copy most of the above code, but make the necessary modifications.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Use five-fold cross validation to estimate the accuracy of the logistic regression model. The logistic regression we're using doesn't have a hyperparameter for us to tune, so just run five-fold CV on it once. Does it outperform either of the support vector classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver = 'lbfgs', penalty = 'none', multi_class='ovr')\n",
    "score = cross_val_score(clf, X, y, cv = 5)\n",
    "print(np.average(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Finally: take the best model you found, according to cross-validation scores, and fit it to the training data. Then make predictions on the testing data and print a confusion matrix. What is the overall test accuracy of the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
